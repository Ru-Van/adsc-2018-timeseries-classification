{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hack to load TensorFlow from system libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 878 µs\n"
     ]
    }
   ],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/usr/lib/python3.6/site-packages/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I run everything from virtual environment, but there's already built package of TensorFlow with CUDA support in ArchLinux repo, so I use it instead of building myself.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mityajj/venv36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.87 s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that it will run on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: ['/device:GPU:0']\n",
      "time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "available_gpus = get_available_gpus()\n",
    "print(\"Available GPUs:\", available_gpus)\n",
    "assert len(available_gpus) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other usual stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 986 µs\n"
     ]
    }
   ],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "with open(\"chunks_neg_1000_900.pickle\", \"rb\") as f:\n",
    "    X_neg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.4 s\n"
     ]
    }
   ],
   "source": [
    "with open(\"chunks_pos_1000_900.pickle\", \"rb\") as f:\n",
    "    X_pos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.43 ms\n"
     ]
    }
   ],
   "source": [
    "y_neg = np.zeros(X_neg.shape[0])\n",
    "y_pos = np.ones(X_pos.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack([X_neg, X_pos])\n",
    "y = np.concatenate((y_neg, y_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.57 ms\n"
     ]
    }
   ],
   "source": [
    "def normalize(X):\n",
    "    X_std = X.std(axis=1, keepdims=True)\n",
    "    X_mean = X.mean(axis=1, keepdims=True)\n",
    "    X_std[np.where(X_std == 0)[0]] = 1\n",
    "    return (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 785 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, \"test\" is actually \"validation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 276 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import (\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling1D,\n",
    "    Reshape,\n",
    ")\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.8 ms\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    inputs = Input(shape=X.shape[1:])\n",
    "    \n",
    "    x = inputs\n",
    "    x = Reshape(X.shape[1:] + (-1,))(x)\n",
    "    x = Conv1D(8, 3, activation=\"relu\")(x)\n",
    "    x = Conv1D(8, 3, activation=\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(16, 3, activation=\"relu\")(x)\n",
    "    x = Conv1D(16, 3, activation=\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Conv1D(32, 3, activation=\"relu\")(x)\n",
    "    x = Conv1D(32, 3, activation=\"relu\")(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dense(10, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    outputs = x\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(lr=0.0008),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample for evaluating performance on a training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "i_train_sample = np.random.choice(range(X_train.shape[0]), size=X_test.shape[0], replace=False)\n",
    "X_train_sample = X_train[i_train_sample]\n",
    "y_train_sample = y_train[i_train_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.37 ms\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5000\n",
    "EPOCHS = 22\n",
    "LOG_EVERY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***N.b.: actually you should not run the next two code cells, they were used to test different architectures and to find out a number of epochs required to reach the optimum.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "m = make_model()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on a part of train set and evaluate both on train and on a validation (called \"test\" here):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_log = pd.DataFrame(columns=[\"epoch\", \"train_auc\", \"test_auc\"])\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1, LOG_EVERY):\n",
    "    m.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=LOG_EVERY)\n",
    "    \n",
    "    yhat_train_sample = m.predict(X_train_sample)\n",
    "    train_auc = roc_auc_score(y_train_sample, yhat_train_sample)\n",
    "    \n",
    "    yhat_test = m.predict(X_test)\n",
    "    test_auc = roc_auc_score(y_test, yhat_test)\n",
    "    \n",
    "    row = (epoch + LOG_EVERY - 1, train_auc, test_auc)\n",
    "    print(\"\\nEPOCH #{} - train AUC {:.3f} test AUC {:.3f}\".format(*row))\n",
    "    \n",
    "    df_log.loc[df_log.shape[0]] = row\n",
    "    \n",
    "    f, a = plt.subplots(figsize=(10, 6))\n",
    "    df_log.set_index(\"epoch\").plot(ax=a, marker=\".\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the real thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model to fit on full train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 1000, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 998, 8)            32        \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 996, 8)            200       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 498, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 496, 16)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 494, 16)           784       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 247, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 245, 32)           1568      \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 243, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 121, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               387300    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 394,409\n",
      "Trainable params: 394,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "m = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit on the full train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "819072/819072 [==============================] - 174s 212us/step - loss: 0.2222\n",
      "Epoch 2/22\n",
      "819072/819072 [==============================] - 170s 208us/step - loss: 0.0838\n",
      "Epoch 3/22\n",
      "819072/819072 [==============================] - 170s 208us/step - loss: 0.0575\n",
      "Epoch 4/22\n",
      "819072/819072 [==============================] - 170s 208us/step - loss: 0.0441\n",
      "Epoch 5/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0362\n",
      "Epoch 6/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0316\n",
      "Epoch 7/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0282\n",
      "Epoch 8/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0281\n",
      "Epoch 9/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0239\n",
      "Epoch 10/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0216\n",
      "Epoch 11/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0196\n",
      "Epoch 12/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0189\n",
      "Epoch 13/22\n",
      "819072/819072 [==============================] - 170s 208us/step - loss: 0.0178\n",
      "Epoch 14/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0215\n",
      "Epoch 15/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0166\n",
      "Epoch 16/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0158\n",
      "Epoch 17/22\n",
      "819072/819072 [==============================] - 171s 209us/step - loss: 0.0148\n",
      "Epoch 18/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0145\n",
      "Epoch 19/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0137\n",
      "Epoch 20/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0130\n",
      "Epoch 21/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0126\n",
      "Epoch 22/22\n",
      "819072/819072 [==============================] - 171s 208us/step - loss: 0.0126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41bc3155c0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 2min 36s\n"
     ]
    }
   ],
   "source": [
    "m.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric on a training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998657225194145"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.5 s\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score(y, m.predict(X, batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data_real = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "X_real = data_real[\"X\"][:, 2:, :]\n",
    "y_real = data_real[\"y\"]\n",
    "names_real = data_real[\"names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 54, 5760), (500,), (500,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "X_real.shape, y_real.shape, names_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treat each of the time series individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 5760)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 578 ms\n"
     ]
    }
   ],
   "source": [
    "X_real = np.vstack(X_real)\n",
    "X_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split them into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.52 ms\n"
     ]
    }
   ],
   "source": [
    "def generate_chunks(l, o):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start + l < X_real.shape[-1]:\n",
    "        chunks.append((start, start + l))\n",
    "        start += (l - o)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "CHUNK_LENGTH = 1000\n",
    "CHUNK_OVERLAP = 900\n",
    "\n",
    "chunks = generate_chunks(CHUNK_LENGTH, CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 98.8 ms\n"
     ]
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 81.7 ms\n"
     ]
    }
   ],
   "source": [
    "i_known = np.where((y_real[:, None] == [0, 1]).max(axis=1))[0]\n",
    "i_unknown = np.where(~(y_real[:, None] == [0, 1]).max(axis=1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate predicts for each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:34<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "yhats_real = []\n",
    "\n",
    "for chunk in tqdm.tqdm(chunks):\n",
    "    yhat_real_one = m.predict(normalize(X_real[:, chunk[0]:chunk[1]]))\n",
    "    yhats_real.append(yhat_real_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.37 ms\n"
     ]
    }
   ],
   "source": [
    "yhat_real = np.hstack(yhats_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smooth with moving average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 376 ms\n"
     ]
    }
   ],
   "source": [
    "MA_PERIOD = 3\n",
    "\n",
    "yhat_convolved = np.vstack([\n",
    "    np.convolve(yhat_real[i], np.ones((MA_PERIOD,)) / MA_PERIOD, mode=\"valid\")\n",
    "    for i in range(yhat_real.shape[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 46)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.11 ms\n"
     ]
    }
   ],
   "source": [
    "yhat_convolved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.13 ms\n"
     ]
    }
   ],
   "source": [
    "yhat_reshaped = yhat_convolved.max(axis=1).reshape(y_real.shape[0], -1).max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate thus created scores on the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800495321959273"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.4 ms\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score(y_real[i_known], yhat_reshaped[i_known])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.5 ms\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Id\": names_real[i_unknown],\n",
    "    \"Attack\": yhat_reshaped[i_unknown],\n",
    "})[[\"Id\", \"Attack\"]].to_csv(\"cnn.980.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.06 ms\n"
     ]
    }
   ],
   "source": [
    "df_y = pd.DataFrame({\n",
    "    \"y\": y_real,\n",
    "    \"yhat\": yhat_reshaped,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.36 ms\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_y\n",
    "    .rename(columns={\"y\": \"Attack\", \"yhat\": \"AttackHat\"})\n",
    "    .to_csv(\"cnn.980.full.csv\", index_label=\"Id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
